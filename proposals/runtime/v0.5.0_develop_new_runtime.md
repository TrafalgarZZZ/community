<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Motivation](#motivation)
- [Goals](#goals)
- [Non-Goals](#non-goals)
- [API](#api)
  - [DataLoad CRD](#dataload-crd)
  - [DataLoad.Status](#dataloadstatus)
- [LifeCycle](#lifecycle)
- [Design](#design)
  - [数据预热前置条件检查](#%E6%95%B0%E6%8D%AE%E9%A2%84%E7%83%AD%E5%89%8D%E7%BD%AE%E6%9D%A1%E4%BB%B6%E6%A3%80%E6%9F%A5)
  - [数据预热Job逻辑设计 - Alluxio](#%E6%95%B0%E6%8D%AE%E9%A2%84%E7%83%ADjob%E9%80%BB%E8%BE%91%E8%AE%BE%E8%AE%A1---alluxio)
- [Test](#test)
- [Alternative Considered](#alternative-considered)
- [Commits](#commits)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## Motivation

为了支持多种Runtime，简化新的Runtime接入成本，最大化重用现有实现。Fluid需要重构整体架构并且梳理声明周期。需要提供：

1. 整个生命周期的描述
2. 新Runtime接入的开发规范
3. 新Runtime接入的样例


数据预热是一个与用户需求强相关的功能特性，用户应当根据自身需求决定：
1. 是否进行数据预热？
2. 何时进行数据预热？
3. 数据预热中待预热的目标数据是什么？
4. 对目标数据进行怎样的预热？（例如，预热时选择多少replication等）

考虑到数据预热在实际场景的复杂性，我们需要实现一个额外的CRD对数据预热的行为进行描述，并将此CRD作为API供用户进行配置。同时，需要额外实现一个新的Controller，对该CRD进行生命周期管理，信息维护和更新，并按用户描述的数据预热行为做出相应的数据加载行为。

## Goals
- 梳理Runtime和Engine的生命周期
- 根据用户的描述完成数据预热
- 数据预热整个过程可被观测，用户可了解到预热的状态
- 支持仅预热部分指定数据
- 支持数据预热时加载至分布式缓存引擎的副本数量
- 可多次重复执行的数据预热

## Non-Goals
- 暂不支持在数据预热时，将数据加载至各个Dataset部署结点的Kernel Cache中的操作
- 暂不支持定时执行数据预热(类似于CronJob)
- 暂不支持在同个数据集上并发执行多个数据预热任务

## API

### DataLoad CRD

```yaml
apiVersion: data.fluid.io/v1alpha1
kind: DataLoad
metadata:
  name: dataload-job1
spec:
  dataset:
    name: dataset
    namespace: default
  loadMetadata: true
  target:
    - path: /train
      replicas: 2
    - path: /test
      replicas: 1
```

该DataLoad CRD的`spec`属性中包括：
- dataset: 需要进行数据预热的Dataset的描述
  - name: 需要进行数据预热的Dataset的名字
  - namespace: 需要进行数据预热的Dataset所在的命名空间，默认设为default
- loadMetadata: 是否需要进行元数据的加载
- target: 需要进行数据预热的目标数据的描述，为一个数组，每个数组元素包括:
  - path: 需要进行数据预热的目标数据在分布式缓存引擎中的路径
  - replicas: 该目标数据在数据预热时加载至分布式缓存的数据副本数量

### DataLoad.Status

```yaml
apiVersion: data.fluid.io/v1alpha1
kind: DataLoad
metadata:
  name: dataload-job1
spec:
  ...
status:
  startTime: "2020-10-22T02:31:21Z"
  completionTime: "2020-10-22T02:33:10Z"
  conditions:
  - lastProbeTime: "2020-10-22T02:33:10Z"
    lastTransitionTime: "2020-10-22T02:33:10Z"
    status: "True"
    type: Complete
  phase: Loaded
```

`phase`属性持久化地记录DataLoad的执行状态，包含以下几个阶段：

- PhaseNone = "": 初始状态
- PhasePending = "Pending", 表示数据预热未开始，正处于等待状态
- PhaseLoading = "Loading", 表示正在进行数据预热
- PhaseLoaded = "Loaded", 表示数据预热已完成
- PhaseFailed = "Failed"， 表示数据预热失败

## Life Cycle Of Runtime

## Life Cycle Of Engine

## 

可以下沉的方法梳理


1. 用户在希望进行数据预热时，提交DataLoad CRD，定义此次数据预热的行为

2. DataLoad controller依据DataLoad CRD中的`dataset`描述(name和namespace信息)，获得对应的Dataset对象,检查该Dataset状态，如果准备就绪，转向步骤3，否则等待Dataset准备就绪

3. 检查是否存在在相同目标数据集上正在运行（即`status.phase`==`PhaseLoading`）的数据预热任务，如果存在,等待其完成;如果不存在，则转向步骤4
   
4. DataLoad controller创建一个Job对象，该Job对象根据Dataset底层分布式缓存引擎的不同可能会使用不同的镜像启动
   
5. Job执行具体的数据预热行为，根据Dataset底层分布式缓存引擎的不同，数据预热的实际执行逻辑可能不同

6. DataLoad controller周期性查询Job运行状态

7. 根据Job运行状态更新DataLoad对象中的状态

## Design

### 数据预热前置条件检查

1. 检查期望进行数据预热的目标Dataset是否存在，如果存在，转向2

2. 检查该Dataset是否已完成文件元信息加载（即`status.ufsTotal` != ""或"[Calculating]"），如果已完成，转向3

3. 检查是否存在在相同目标数据集上正在运行的数据预热任务，如果不存在，转向4

4. 检查该Dataset绑定的分布式缓存引擎是否就绪。对于Alluxio，可使用`alluxio fsadmin report`进行检查，如果已就绪,则可以创建Job进行数据预热

### 数据预热Job逻辑设计 - Alluxio

Job对象将由DataLoad controller以`helm install`的方式创建。创建前，需要经过以下判断，根据不同的情况生成不同的`chart valus`以控制该Job的行为:

1. 如果DataLoad CRD中设置`spec.loadMetadata`为`true`，并且在`target`中的目标预热目录包含以FluidNative方式(即主机目录和PVC方式)挂载的数据集，那么生成的Job对象需要以`hostPath`方式挂载这些目录。Job在执行任意步骤前，需要首先进行`du -sh`操作保证这些目录下文件元信息的同步。

2. 在Job实际执行分布式数据加载前，需要对指定目录进行最大副本数量(`replicationMax`)调整，否则在进行指定副本数量的分布式数据加载时，多余的副本数量会被迅速Evict。Job执行`alluxio fs setReplication --max <target[i].replicas> <target[i].path>`

3. 如果DataLoad CRD中设置`spec.loadMetadata`为`true`，对于每一个`target`中的目标预热目录，Job将执行`alluxio fs distributedLoad -Dalluxio.user.file.metadata.sync.interval=0 --replication <target[i].replicas> <target[i].path>`命令进行文件元信息的同步并执行分布式数据加载操作，否则Job执行`alluxio fs distributedLoad --replication <target[i].replicas> <target[i].path>`命令仅执行分布式数据加载操作

## Test

验证目标：

1. 分布式加载过程可通过查看数据缓存情况被观测
2. 通过`alluxio fs ls`可验证仅部分数据被成功加载的结果
3. `status.phase`应当与整个数据预热过程保持一致

## Alternative Considered 
对于Alluxio缓存引擎进行分布式数据缓存加载的另一种实现方案为`alluxio setReplication --min <target[i].replicas> <target[i].path>`，这种方案面临两个问题：
  
  1. 无法准确知晓数据的分布式加载是否已经完成
  2. 改变了Alluxio中被加载文件的`minReplication`,可能会导致这部分数据长期留存，不会被Evict

对于Alluxio这种分布式数据缓存引擎，我们使用`alluxio fs distributedLoad`作为数据预热的实现，目前该命令是同步的，更好的方案或许为异步的分布式数据加载，这需要Alluxio提供额外的支持

另外，是否在DataLoad CRD中提供更细粒度的缓存副本数量控制(e.g. 允许用户设置min和max)需要进一步讨论
## Commits

